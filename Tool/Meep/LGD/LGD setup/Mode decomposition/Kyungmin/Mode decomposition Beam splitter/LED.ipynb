{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bd27603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meep as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from autograd import numpy as npa\n",
    "from autograd import tensor_jacobian_product, grad\n",
    "import meep as mp\n",
    "import meep.adjoint as mpa\n",
    "import numpy as np\n",
    "from autograd import numpy as npa\n",
    "from autograd import tensor_jacobian_product, grad\n",
    "import nlopt\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import math\n",
    "import meep.adjoint as mpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "15c45bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontlabel = 16\n",
    "\n",
    "lambda_min = 0.4       # 최소 파장 (µm)\n",
    "lambda_max = 0.7       # 최대 파장 (µm)\n",
    "fmin = 1/lambda_max    # 최소 주파수\n",
    "fmax = 1/lambda_min    # 최대 주파수\n",
    "fcen = 0.5*(fmin+fmax) # 중앙 주파수\n",
    "\n",
    "resolution = 50        # 시뮬레이션 해상도\n",
    "design_region_resolution = 50\n",
    "\n",
    "# nfreq = 50             # 추출할 주파수 개수\n",
    "df = fmax-fmin         # 주파수 대역폭\n",
    "\n",
    "# df = 0\n",
    "nfreq = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dd29c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpml = 0.5\n",
    "tsio2 = 3\n",
    "tair = 3\n",
    "\n",
    "design_region_height = 0.5\n",
    "design_region_width = 2\n",
    "\n",
    "Sx = 2\n",
    "Sy = tsio2+tair\n",
    "\n",
    "sio2 = mp.Medium(index = 1.45)\n",
    "air = mp.Medium(index = 1)\n",
    "\n",
    "boundary_layers = [mp.PML(thickness = tpml, direction = mp.Y)]\n",
    "\n",
    "Nx = int(100)\n",
    "Ny = int(1)\n",
    "\n",
    "design_region_resolution=Nx/design_region_width\n",
    "\n",
    "y_bottom = -Sy / 2\n",
    "center_y_sio2 = y_bottom + tsio2/2\n",
    "center_y_air = y_bottom + tsio2+ tair/2\n",
    "\n",
    "width_sio2 = Sx\n",
    "width_air = Sx\n",
    "\n",
    "cell_size = mp.Vector3(Sx, Sy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c0e0ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [\n",
    "    # SiO2 layer\n",
    "    mp.Block(\n",
    "        material=sio2,\n",
    "        size=mp.Vector3(width_sio2, tsio2, 0),\n",
    "        center=mp.Vector3(0, center_y_sio2, 0)\n",
    "    ),\n",
    "    mp.Block(\n",
    "        material=air,\n",
    "        size=mp.Vector3(width_air, tair, 0),\n",
    "        center=mp.Vector3(0, center_y_air, 0)\n",
    "    ),\n",
    "]\n",
    "\n",
    "region_height_each = design_region_height     # = 0.5\n",
    "\n",
    "design_variables = mp.MaterialGrid(\n",
    "        mp.Vector3(Nx, Ny),\n",
    "        air,\n",
    "        sio2,\n",
    "        grid_type=\"U_MEAN\",\n",
    "        do_averaging=False\n",
    "    )\n",
    "\n",
    "design_region = mpa.DesignRegion(\n",
    "    design_variables,\n",
    "    volume=mp.Volume(\n",
    "        center=mp.Vector3(0, 0, 0),\n",
    "        size=mp.Vector3(design_region_width, region_height_each, 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "geometry.append(\n",
    "    mp.Block(\n",
    "        material=design_variables,\n",
    "        size=design_region.size,\n",
    "        center=design_region.center\n",
    "    )\n",
    ")\n",
    "\n",
    "sources = [\n",
    "    mp.Source(\n",
    "        mp.GaussianSource(frequency=fcen, fwidth=df, is_integrated=True),\n",
    "        component=mp.Ez,\n",
    "        center=mp.Vector3(0, -2.5+2/resolution, 0),\n",
    "        size = mp.Vector3(Sx, 0,0 )\n",
    "    )\n",
    "]\n",
    "\n",
    "k0 = mp.Vector3(0,0,0)\n",
    "\n",
    "sim = mp.Simulation(\n",
    "    resolution = resolution,\n",
    "    cell_size = cell_size,\n",
    "    sources = sources,\n",
    "    boundary_layers = boundary_layers,\n",
    "    geometry = geometry,\n",
    "    k_point = k0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a9df041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_y      = 2\n",
    "line_len   = Sx \n",
    "monitor_sz = mp.Vector3(line_len, 0, 0)\n",
    "\n",
    "ff_45 = mpa.FourierFields(\n",
    "    sim,\n",
    "    mp.Volume(center=mp.Vector3(0, mon_y, 0), size=monitor_sz),\n",
    "    mp.Ez,\n",
    "    yee_grid=True\n",
    ")\n",
    "\n",
    "# --- 상수/파라미터 ---\n",
    "theta_deg = 45.0\n",
    "n_bg  = 1.0                            # 모니터 쪽 매질 굴절률(공기면 1)\n",
    "k0    = 2 * np.pi * fcen * n_bg\n",
    "dx    = 1.0 / resolution\n",
    "\n",
    "# 각도 창 폭(표준편차) 설정: 대략 ±5~8° 범위\n",
    "angle_halfwidth_deg = 6.0\n",
    "sigma_kx = k0 * np.cos(np.deg2rad(theta_deg)) * np.deg2rad(angle_halfwidth_deg)\n",
    "\n",
    "# 0° 억제용 좁은 창\n",
    "sigma0_kx = 0.05 * k0\n",
    "\n",
    "def J_45(fields_line):\n",
    "    # 라인 위 필드 → kx 스펙트럼\n",
    "    Ez = fields_line\n",
    "    N  = Ez.size\n",
    "    Ek = np.fft.fftshift(np.fft.fft(Ez)) * dx\n",
    "    kx = 2*np.pi * np.fft.fftshift(np.fft.fftfreq(N, d=dx))\n",
    "    Ik = np.abs(Ek)**2\n",
    "\n",
    "    # 타깃 윈도우(+45°)\n",
    "    kx_t = k0 * np.sin(np.deg2rad(theta_deg))\n",
    "    Wt   = np.exp(-((kx - kx_t)**2) / (2*sigma_kx**2))\n",
    "\n",
    "    # 0° 억제\n",
    "    W0   = np.exp(-(kx**2) / (2*sigma0_kx**2))\n",
    "\n",
    "    Pt   = np.sum(Ik) + 1e-18\n",
    "    P_tg = np.sum(Ik * Wt) / Pt       # 목표 각도 정규화 파워\n",
    "    P0   = np.sum(Ik * W0) / Pt       # 0° 정규화 파워\n",
    "    Prest= 1.0 - P_tg                  # 타깃 외 파워(정규화)\n",
    "\n",
    "    # 가중치 (필요 시 조정)\n",
    "    alpha = 0.5   # 바깥 대역 패널티\n",
    "    gamma = 0.2   # 0° 패널티\n",
    "\n",
    "    # 최종 FoM (maximize)\n",
    "    F = P_tg - alpha*Prest - gamma*P0\n",
    "    return F\n",
    "\n",
    "\n",
    "opt = mpa.OptimizationProblem(\n",
    "        simulation=sim,\n",
    "        objective_functions=[J_45],\n",
    "        objective_arguments=[ff_45],\n",
    "        design_regions=[design_region],  \n",
    "        frequencies=[fcen],\n",
    "        maximum_run_time=100,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7fc0dfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt.plot2D(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3ea6bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self, lr=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8, warmup_iters=10):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.mt = None\n",
    "        self.vt = None\n",
    "        self.iter = 0\n",
    "        self.warmup_iters = warmup_iters\n",
    "    \n",
    "    def update(self, v, gradient):\n",
    "        if self.mt is None:\n",
    "            self.mt = np.zeros_like(v)\n",
    "        if self.vt is None:\n",
    "            self.vt = np.zeros_like(v)\n",
    "            \n",
    "        #Adam에서는 기울기 값과 기울기의 제곱값의 지수이동평균을 활용하여 step 변회량을 조절\n",
    "        self.iter += 1\n",
    "        self.mt = self.beta1 * self.mt + (1 - self.beta1) * gradient           #m_(t)=beta_(1)*m_(t-1)+(1-beta_(1))*gradient\n",
    "        self.vt = self.beta2 * self.vt + (1 - self.beta2) * (gradient ** 2)       #v_(t)=beta_(2)*v_(t-1)+(1-beta_(2))*(gradeint^2)\n",
    "         \n",
    "        # 초기 몇번의 update에서 0으로 편향되어 있어서 출발 지점에서 멀리 떨어진 곳으로 이동하는, 초기 경로의 편향 문제를 해결 하기 위해 unbiased하게 만들어줌\n",
    "        m_hat = self.mt / (1 - self.beta1 ** self.iter)   #m_hat=m/(1-beta1**t)\n",
    "        v_hat = self.vt / (1 - self.beta2 ** self.iter)\n",
    "        \n",
    "        # Warm-up 단계\n",
    "        if self.iter <= self.warmup_iters:\n",
    "            warmup_factor = self.iter / self.warmup_iters\n",
    "            lr = self.lr * warmup_factor\n",
    "        else:\n",
    "            lr = self.lr   #lr_t <- alpha*sqrt\n",
    "            \n",
    "        #update = self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "        update_factor= m_hat / (np.sqrt(v_hat) + self.epsilon) #theta_t <- theta_(t-1)-alpha_(t)*m_(t)/(sqrt(v_(t))+epsilon) alpha_(t)=learning rate\n",
    "        update = lr * update_factor\n",
    "        updated_v = v + update\n",
    "        updated_v = np.clip(updated_v, 0.0, 1.0)\n",
    "        \n",
    "        adam_lr=np.mean(np.abs(update))\n",
    "        adam_uf=np.mean(np.abs(update_factor))\n",
    "        \n",
    "        # adam_beta1=self.beta1\n",
    "        # # adam_beta2=self.beta2\n",
    "        adam_m=self.mt\n",
    "        adam_v=self.vt\n",
    "        adam_t=self.iter\n",
    "        \n",
    "        return updated_v, adam_lr, adam_uf, adam_m, adam_v, adam_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ea08794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 1\n",
    "eta_i = 0.5\n",
    "\n",
    "def multi_mapping(x, eta, beta):    \n",
    "    size_each = Nx * Ny\n",
    "\n",
    "    v3 = x.reshape(layer_num, size_each)\n",
    "\n",
    "    rho_list = []\n",
    "    for i in range(layer_num):\n",
    "        layer_field = v3[i].reshape(Nx, Ny)\n",
    "        sym_field   = (layer_field[::-1, :] + layer_field) / 2\n",
    "        flat        = sym_field.ravel()\n",
    "        proj        = mpa.tanh_projection(flat, beta, eta)\n",
    "        rho_list.append(proj)\n",
    "\n",
    "    return npa.concatenate(rho_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "790d2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iter 1 ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'opt_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[205], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m Max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cur_iter[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m Max_iter:\n\u001b[0;32m--> 128\u001b[0m     x, cur_beta \u001b[38;5;241m=\u001b[39m \u001b[43mf_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_beta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binarization_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.95\u001b[39m:\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreshold reached → final mapping with β=∞\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[205], line 43\u001b[0m, in \u001b[0;36mf_multi\u001b[0;34m(v, eta, beta)\u001b[0m\n\u001b[1;32m     41\u001b[0m f0_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     42\u001b[0m dJ_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mopt_list\u001b[49m)):\n\u001b[1;32m     44\u001b[0m     f0_i, dJ_i \u001b[38;5;241m=\u001b[39m opt_list[i]([rho_full], need_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, need_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, beta\u001b[38;5;241m=\u001b[39mbeta)\n\u001b[1;32m     45\u001b[0m     f0_list\u001b[38;5;241m.\u001b[39mappend(f0_i\u001b[38;5;241m.\u001b[39mflatten())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opt_list' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "\n",
    "n = Nx * layer_num\n",
    "np.random.seed(5)\n",
    "# x = 0.4 + 0.2 * np.random.rand(n)  \n",
    "x = np.ones(n)*0.5\n",
    "\n",
    "frames_dir = \"frames\"\n",
    "os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "# 저장된 프레임 파일명 리스트\n",
    "frame_files = []\n",
    "\n",
    "cur_beta = 5\n",
    "\n",
    "cur_iter             = [0]\n",
    "evaluation_history   = []\n",
    "beta_history         = []\n",
    "binarization_history = []\n",
    "\n",
    "g_histories   = [[] for _ in range(layer_num)]\n",
    "x_histories   = [[] for _ in range(layer_num)]\n",
    "lr_histories  = [[] for _ in range(layer_num)]\n",
    "uf_histories  = [[] for _ in range(layer_num)]\n",
    "t_histories   = [[] for _ in range(layer_num)]\n",
    "\n",
    "optimizers = [AdamOptimizer(lr=0.02, beta1=0.9) for _ in range(layer_num)]\n",
    "\n",
    "def f_multi(v, eta, beta):\n",
    "    print(f\"\\n--- Iter {cur_iter[0]+1} ---\")\n",
    "\n",
    "    rho_full = multi_mapping(v, eta, beta)\n",
    "\n",
    "    bin_deg = np.sum(np.abs(rho_full - 0.5)) / (0.5 * rho_full.size)\n",
    "    binarization_history.append(bin_deg)\n",
    "\n",
    "    size_each = Nx * Ny\n",
    "    rho_list = [rho_full[i * size_each:(i + 1) * size_each] for i in range(layer_num)]\n",
    "\n",
    "    f0_list = []\n",
    "    dJ_list = []\n",
    "    for i in range(len(opt_list)):\n",
    "        f0_i, dJ_i = opt_list[i]([rho_full], need_value=True, need_gradient=True, beta=beta)\n",
    "        f0_list.append(f0_i.flatten())\n",
    "        dJ_list.append(dJ_i)\n",
    "\n",
    "    dJ_total = np.mean(dJ_list, axis=0) # -> 3번째 트라이 바꾸는 부분\n",
    "    dJ_flat = np.array(dJ_total).flatten()\n",
    "\n",
    "    gradient_full = tensor_jacobian_product(multi_mapping, 0)(v, eta, beta, dJ_flat)\n",
    "\n",
    "    grad_list = [gradient_full[i * size_each:(i + 1) * size_each] for i in range(layer_num)]\n",
    "    vs = v.reshape(layer_num, size_each)\n",
    "    v_new_layers = []\n",
    "    for i in range(layer_num):\n",
    "        vi_new, lr, uf, m, vt, t = optimizers[i].update(vs[i], grad_list[i])\n",
    "        lr_histories[i].append(lr)\n",
    "        uf_histories[i].append(uf)\n",
    "        t_histories[i].append(t)\n",
    "        g_histories[i].append(grad_list[i].copy())\n",
    "        x_histories[i].append(vi_new.copy())\n",
    "        v_new_layers.append(vi_new)\n",
    "    v_new = np.concatenate(v_new_layers)\n",
    "\n",
    "    f_vals = [float(np.abs(f0).item()) for f0 in f0_list]\n",
    "    evaluation_history.append(f_vals)\n",
    "\n",
    "    beta_history.append(beta)\n",
    "    cur_iter[0] += 1\n",
    "\n",
    "    if len(evaluation_history) >= 3:\n",
    "        f_prev2 = evaluation_history[-3]\n",
    "        f_prev1 = evaluation_history[-2]\n",
    "        f_curr  = evaluation_history[-1]\n",
    "\n",
    "        bin_prev2 = binarization_history[-3]\n",
    "        bin_prev1 = binarization_history[-2]\n",
    "        bin_curr  = binarization_history[-1]\n",
    "\n",
    "        # FoM 기준 변화율 계산 (여기 부분 계속 수정중)\n",
    "        change1 = abs(np.mean(f_curr)  - np.mean(f_prev1)) / (abs(np.mean(f_prev1)) + 1e-12)\n",
    "        change2 = abs(np.mean(f_prev1) - np.mean(f_prev2)) / (abs(np.mean(f_prev2)) + 1e-12)\n",
    "\n",
    "        bin_change1 = abs(bin_curr  - bin_prev1) / (abs(bin_prev1) + 1e-12)\n",
    "        bin_change2 = abs(bin_prev1 - bin_prev2) / (abs(bin_prev2) + 1e-12)\n",
    "\n",
    "        if (change1 < 0.003 and change2 < 0.003) and (bin_change1 < 0.001 and bin_change2 < 0.00075):\n",
    "            if beta < 8:\n",
    "                beta *= 1.3\n",
    "            else:\n",
    "                beta = beta + 5*np.tanh((beta - 0.5)*0.03)\n",
    "\n",
    "    print(f\"Current β: {beta:.3f}\")\n",
    "    print(\"FoM values:\", f_vals)\n",
    "    print(f\"Mean FoM: {np.mean(f_vals):.6f}\")\n",
    "\n",
    "    print(f\"Binarization degree: {bin_deg:.4f}\")\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    opt_list[0].plot2D(\n",
    "        False,\n",
    "        output_plane=mp.Volume(\n",
    "            size=mp.Vector3(design_region_width, region_height_each * layer_num - 1 / resolution, 0),\n",
    "            center=mp.Vector3(0, full_center_y, 0)\n",
    "        ),\n",
    "        ax=ax,\n",
    "        show_sources=False,\n",
    "        show_monitors=False,\n",
    "        show_boundary_layers=False,\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # 2) 프레임으로 저장하기\n",
    "    frame_filename = os.path.join(frames_dir, f\"frame_{cur_iter[0]:03d}.png\")\n",
    "    fig.savefig(frame_filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    frame_files.append(frame_filename)\n",
    "\n",
    "    return v_new, beta\n",
    "\n",
    "mp.verbosity(0)\n",
    "Max_iter = 30\n",
    "\n",
    "while cur_iter[0] < Max_iter:\n",
    "    x, cur_beta = f_multi(x, eta_i, cur_beta)\n",
    "    if binarization_history[-1] > 0.95:\n",
    "        print(\"Threshold reached → final mapping with β=∞\")\n",
    "        x, _ = f_multi(x, eta_i, np.inf)\n",
    "        print(\"FOM increases : \", )\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6aa98d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iter 1 ---\n",
      "Starting forward run...\n",
      "Starting adjoint run...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not ArrayBox",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[206], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m Max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cur_iter[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m Max_iter:\n\u001b[0;32m---> 99\u001b[0m     x, cur_beta \u001b[38;5;241m=\u001b[39m \u001b[43mf_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_beta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binarization_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.95\u001b[39m:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreshold reached → final mapping with β=∞\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[206], line 14\u001b[0m, in \u001b[0;36mf_multi\u001b[0;34m(v, eta, beta)\u001b[0m\n\u001b[1;32m      9\u001b[0m size_each \u001b[38;5;241m=\u001b[39m Nx \u001b[38;5;241m*\u001b[39m Ny\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# (참고) 필요 없다면 rho_list는 삭제 가능\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# rho_list = [rho_full[i * size_each:(i + 1) * size_each] for i in range(layer_num)]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# --- 단일 opt 호출로 FoM, gradient 계산 ---\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m f0, dJ \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrho_full\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 리스트 형태 유지(나중 평균/변화율 계산 로직 그대로 쓰려고)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m f_vals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mabs(f0)\u001b[38;5;241m.\u001b[39mitem())]\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/meep/adjoint/optimization_problem.py:215\u001b[0m, in \u001b[0;36mOptimizationProblem.__call__\u001b[0;34m(self, rho_vector, need_value, need_gradient, beta)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFWD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting adjoint run...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjoint_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating gradient...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_gradient()\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/meep/adjoint/optimization_problem.py:310\u001b[0m, in \u001b[0;36mOptimizationProblem.adjoint_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madjoint_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;66;03m# set up adjoint sources and monitors\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_adjoint_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# flip the m number\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39m_check_if_cylindrical(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim):\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/meep/adjoint/optimization_problem.py:301\u001b[0m, in \u001b[0;36mOptimizationProblem.prepare_adjoint_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ar \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_functions)):\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mi, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective_arguments):\n\u001b[0;32m--> 301\u001b[0m         dJ \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_functions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;66;03m# get gradient of objective w.r.t. monitor\u001b[39;00m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(dJ):\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/autograd/differential_operators.py:60\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjacobian\u001b[39m(fun, x):\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    Returns a function which computes the Jacobian of `fun` with respect to\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    positional argument number `argnum`, which must be a scalar or array. Unlike\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    (out1, out2, ...) then the Jacobian has shape (out1, out2, ..., in1, in2, ...).\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     ans_vspace \u001b[38;5;241m=\u001b[39m vspace(ans)\n\u001b[1;32m     62\u001b[0m     jacobian_shape \u001b[38;5;241m=\u001b[39m ans_vspace\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m vspace(x)\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/autograd/core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[1;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[0;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/autograd/tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[0;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/autograd/wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[201], line 29\u001b[0m, in \u001b[0;36mJ_45\u001b[0;34m(fields_line)\u001b[0m\n\u001b[1;32m     27\u001b[0m Ez \u001b[38;5;241m=\u001b[39m fields_line\n\u001b[1;32m     28\u001b[0m N  \u001b[38;5;241m=\u001b[39m Ez\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m---> 29\u001b[0m Ek \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfftshift(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEz\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m dx\n\u001b[1;32m     30\u001b[0m kx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfftshift(np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfftfreq(N, d\u001b[38;5;241m=\u001b[39mdx))\n\u001b[1;32m     31\u001b[0m Ik \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(Ek)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:215\u001b[0m, in \u001b[0;36mfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    213\u001b[0m     n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m    214\u001b[0m inv_norm \u001b[38;5;241m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[0;32m--> 215\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_fft\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/mp/lib/python3.9/site-packages/numpy/fft/_pocketfft.py:70\u001b[0m, in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     67\u001b[0m         a \u001b[38;5;241m=\u001b[39m z\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m a\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mpfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     a \u001b[38;5;241m=\u001b[39m swapaxes(a, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not ArrayBox"
     ]
    }
   ],
   "source": [
    "def f_multi(v, eta, beta):\n",
    "    print(f\"\\n--- Iter {cur_iter[0]+1} ---\")\n",
    "\n",
    "    rho_full = multi_mapping(v, eta, beta)\n",
    "\n",
    "    bin_deg = np.sum(np.abs(rho_full - 0.5)) / (0.5 * rho_full.size)\n",
    "    binarization_history.append(bin_deg)\n",
    "\n",
    "    size_each = Nx * Ny\n",
    "    # (참고) 필요 없다면 rho_list는 삭제 가능\n",
    "    # rho_list = [rho_full[i * size_each:(i + 1) * size_each] for i in range(layer_num)]\n",
    "\n",
    "    # --- 단일 opt 호출로 FoM, gradient 계산 ---\n",
    "    f0, dJ = opt([rho_full], need_value=True, need_gradient=True, beta=beta)\n",
    "\n",
    "    # 리스트 형태 유지(나중 평균/변화율 계산 로직 그대로 쓰려고)\n",
    "    f_vals = [float(np.abs(f0).item())]\n",
    "    evaluation_history.append(f_vals)\n",
    "\n",
    "    # dJ_total 은 바로 dJ 사용(평균 불필요)\n",
    "    dJ_total = dJ\n",
    "    dJ_flat  = np.asarray(dJ_total).ravel()\n",
    "\n",
    "    # 체인룰로 design 변수 그레이디언트\n",
    "    gradient_full = tensor_jacobian_product(multi_mapping, 0)(v, eta, beta, dJ_flat)\n",
    "\n",
    "    # 레이어별로 나눠서 Adam 업데이트\n",
    "    grad_list = [gradient_full[i * size_each:(i + 1) * size_each] for i in range(layer_num)]\n",
    "    vs = v.reshape(layer_num, size_each)\n",
    "    v_new_layers = []\n",
    "    for i in range(layer_num):\n",
    "        vi_new, lr, uf, m, vt, t = optimizers[i].update(vs[i], grad_list[i])\n",
    "        lr_histories[i].append(lr)\n",
    "        uf_histories[i].append(uf)\n",
    "        t_histories[i].append(t)\n",
    "        g_histories[i].append(grad_list[i].copy())\n",
    "        x_histories[i].append(vi_new.copy())\n",
    "        v_new_layers.append(vi_new)\n",
    "    v_new = np.concatenate(v_new_layers)\n",
    "\n",
    "    beta_history.append(beta)\n",
    "    cur_iter[0] += 1\n",
    "\n",
    "    # --- β 업데이트 로직 그대로 유지 ---\n",
    "    if len(evaluation_history) >= 3:\n",
    "        f_prev2 = evaluation_history[-3]\n",
    "        f_prev1 = evaluation_history[-2]\n",
    "        f_curr  = evaluation_history[-1]\n",
    "\n",
    "        bin_prev2 = binarization_history[-3]\n",
    "        bin_prev1 = binarization_history[-2]\n",
    "        bin_curr  = binarization_history[-1]\n",
    "\n",
    "        change1 = abs(np.mean(f_curr)  - np.mean(f_prev1)) / (abs(np.mean(f_prev1)) + 1e-12)\n",
    "        change2 = abs(np.mean(f_prev1) - np.mean(f_prev2)) / (abs(np.mean(f_prev2)) + 1e-12)\n",
    "\n",
    "        bin_change1 = abs(bin_curr  - bin_prev1) / (abs(bin_prev1) + 1e-12)\n",
    "        bin_change2 = abs(bin_prev1 - bin_prev2) / (abs(bin_prev2) + 1e-12)\n",
    "\n",
    "        if (change1 < 0.003 and change2 < 0.003) and (bin_change1 < 0.001 and bin_change2 < 0.00075):\n",
    "            if beta < 8:\n",
    "                beta *= 1.3\n",
    "            else:\n",
    "                beta = beta + 5*np.tanh((beta - 0.5)*0.03)\n",
    "\n",
    "    print(f\"Current β: {beta:.3f}\")\n",
    "    print(\"FoM values:\", f_vals)\n",
    "    print(f\"Mean FoM: {np.mean(f_vals):.6f}\")\n",
    "    print(f\"Binarization degree: {bin_deg:.4f}\")\n",
    "\n",
    "    # --- 시각화: opt_list[0] → opt 로 변경 ---\n",
    "    fig = plt.figure(figsize=(3, 2))\n",
    "    ax = plt.gca()\n",
    "    opt.plot2D(\n",
    "        False,\n",
    "        output_plane=mp.Volume(\n",
    "            size=mp.Vector3(design_region_width, region_height_each * layer_num - 1 / resolution, 0),\n",
    "            center=mp.Vector3(0, full_center_y, 0)\n",
    "        ),\n",
    "        ax=ax,\n",
    "        show_sources=False,\n",
    "        show_monitors=False,\n",
    "        show_boundary_layers=False,\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    frame_filename = os.path.join(frames_dir, f\"frame_{cur_iter[0]:03d}.png\")\n",
    "    fig.savefig(frame_filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    frame_files.append(frame_filename)\n",
    "\n",
    "    return v_new, beta\n",
    "\n",
    "mp.verbosity(0)\n",
    "Max_iter = 30\n",
    "\n",
    "while cur_iter[0] < Max_iter:\n",
    "    x, cur_beta = f_multi(x, eta_i, cur_beta)\n",
    "    if binarization_history[-1] > 0.95:\n",
    "        print(\"Threshold reached → final mapping with β=∞\")\n",
    "        x, _ = f_multi(x, eta_i, np.inf)\n",
    "        print(\"FOM increases : \", )\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f60902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
